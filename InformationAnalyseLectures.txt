Методы и алгоритмы анализа данных
Воробьев

# Лекция 1
	Задачи машинного обучения:
	1. Прогнозирование показателей (регрессия)
		Предсказание параметров по имеющимся данным.
	2. Классификация (в том числе изображений)
		Разделение входных объектов по классам.
	3. Генеративные задачи
		Добавление к существующим объектов новых. Например фильтры фотографий
	4. Задачи управления
	
	Все алгоритмы машинного обучения можно разделить на 3 класса:
	1. Обучение с учителем (superviser learning)
		Обучение проводится на множестве пар вида: (x, y),
		где x - пример
		y - ответ на данный пример
		X(n+1) -> M -> y(n+1)
		(Lecture1Picts.jpg_Page-1)
			- Классификация (прямая, разделяющая классы)
			- Задача регрессии (прямая, наиболее точно описывающая входные данные)
	2. Обучение без учителя (unsupervised learning)
		Обучение проводится на множестве x, без правильных ответов
		Обучение проводится без вмешательства из вне. Известно описание множества объектов (обучающая выборка). Необходимо установить внутренние взаимосвязи и закономерности, наблюдаемые в этой выборке.
		Основные решаемые задачи:
			- Кластеризация
			- Сокращение размерности данных
			- Обобщение
			- Визуализация данных
	3. Обучение с подкреплением (reinforcment learning)
		Существует среда, в которой происходит обучение
		Система обучается взаимодействуя со средой. Обратная связь обеспечивается с помощью подкрепляющей функции. В отличии от обучения с учителем, на вход не подается значение целевого показателя, только независимые данные. Обучение происходит за счет взаимодействия с некоторой внешней средой.
	
	Стандартный способ решения задачи:
	1. Постановка задачи;
	2. Сбор данных. Они могут быть любыми;
	3. Предварительная обработка: фильтрация, нормализация, выкидывание лишних точек;
	4. Формирование признаков;
	5. Выбор и обучение модели;
	6. Оценка модели. Обычно выполняется несколькими способами;
	7. В зависимости от полученной модели принимается решение о ее внедрении или переходе на еще одну итерацию.
	
	Стек ПО:
		* Питон
		* Numpy, pandas, scipylearn, keros, tenzorflow

# Лекция 2

	Общая модель нейронной сети:
	* Активационная функция
		Добавляет нелинейность в систему уровнений. За счет этого все работает.
		Как выбрать функцию?
			Сигмоида для вероятности (выходной слой)
			Выбрать, основываясь на теории маловероятно. Скорее это эмпирический вывод.
	
	Виды нейронных сетей
	* Полносвязные
		Классификация и регрессия
	* Сверточные
		Ядро свертки. Остальное подброднее потом
	* Рекуррентные
		LSTM. Используют предыдущее значение сети и 
		Машинный перевод
		Для временных рядов
	
	Машина Больцмана
		Выставление начальных значений в сети. Слишком большие приведут к нестабильности. Слишком маленькие - машина не сможет учиться. Маловероятно, что она нужна.
		
	Обучение нейронной сети
		1. Инициализация первичными значениями
		2. Вычисляется выход сети. Сравнивается с идеальным вариантом. Меняются веса
		Learning rate - определяет насколько быстро меняются коэффициенты
		
		> Мягкое значение для функции. Потом передача ошибки для корректировки весов. Также сигнал передается на кванторатор (quantizer) для вывода
		
		> Схождение к глобальному экстремуму. Возможно неплохо выглядят генетические алгоритмы.
		> Метод квадратов для целевой функции. Целевая функция - выходное значение всей нейронной сети для сравнения с реальным. Целевая фунция показывает на сколько неправильно работает нейронная сеть. Используется для перерасчета весов.
		
		Методы отимизации на основе градиентного спука:
			* SGD
			* RMSProp
			* Adam
		
	> Логистическая регрессия
		Сигмоида. Для классификации. Обычно для выходного слоя.
		
	Переобучение overfitting приводит к излишне точному повторению обучающей выборки.
		Большая дисперсия сети. Бороться можно через Регуляризацию. Добавляем дополнительный штраф в функцию. Выбираем наименьшие значения. L2 регуляр